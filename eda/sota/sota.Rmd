---
title: SOTA
author: Sara Altman 
date: "`r Sys.Date()`"
output: 
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
# Libraries
library(tidyverse)
library(lubridate)

# Parameters
file_sota <- here::here("data/sota/sota.rds")
file_sota_unfiltered <- here::here("data/sota/sota_unfiltered.rds")
#===============================================================================

sota <- 
  file_sota %>% 
  read_rds()

sota_unfiltered <-
  file_sota_unfiltered %>% 
  read_rds()
```

## Missing data and repeated benchmarks

The original data had `r nrow(sota_unfiltered)` measurements. However, many rows are missing critical data, including the paper data, metric name, or metric value.

```{r}
sota_unfiltered %>% 
  summarize_at(
    vars(paper_date, metric_name, metric_result), 
    list(missing = ~ sum(is.na(.)), percent = ~ sum(is.na(.)) / n() * 100)
  ) %>% 
  pivot_longer(
    cols = everything(), 
    names_to = c("variable", "measure"),
    names_pattern = "(.*)_(\\w+$)",
    values_to = "value"
  ) %>% 
  pivot_wider(names_from = measure, values_from = value) %>% 
  rename(num_missing = missing, percent_missing = percent) %>% 
  arrange(desc(percent_missing))
```

There are `r sota_unfiltered %>% filter_at(vars(paper_date, metric_result, metric_name), any_vars(is.na(.))) %>% nrow()` rows where at least one of these variables is mising.

I removed these rows, since we can't use them. There also should only be one benchmark measurement per task/metric combination per day. However, sometimes a paper is entered in the data multiple times, with one entry per model put forward in the paper. We only want to keep the model that performed the best.

For example, there are 10 measurement of Average Treatment Effect Error on a causal inference task on one day.

```{r}
sota_unfiltered %>%
  filter_at(
    vars(paper_date, metric_result, metric_name), 
    all_vars(!is.na(.))
  ) %>% 
  count(paper_date, task, metric_name, sort = TRUE) 
```

```{r}
sota_unfiltered %>% 
  filter(
    paper_date == ymd("2016-06-13"), 
    task == "Causal Inference",
    metric_name == "Average Treatment Effect Error"
  ) %>% 
  select(paper_date, paper_title, model_name)
```

These measurements are from different models from the same paper. It might also be important to note that `paper_id` is _not_ a unique identifier. For example, this paper has 10 different values of `paper_id`, one for each model. 

In the final data, for each task-metric-day combination, I included only the data from the best-performing model. This eliminates around 20% of the data, leaving us with `r nrow(sota)` data points.

## Measurements by category

```{r}
observations <-
  sota %>% 
  drop_na(metric_name, metric_result) %>% 
  count(benchmark_id, metric_name, sort = TRUE)

observations %>% 
  ggplot(aes(n)) +
  geom_histogram(binwidth = 1) +
  labs(
    title = 
      "Distribution of the number of times a metric is measured for a task",
    subtitle = "Many metrics are measured only once"
  )
```

```{r}
percent_only_one <-
  observations %>% 
  count(one = n == 1, sort = TRUE) %>% 
  summarize(percent = n[one] / sum(n) * 100) %>% 
  pull(percent) %>% 
  format(digits = 5)
```

`r percent_only_one`% of metrics are measured only once, which means we can't understand their trend over time. 

```{r}
observations_by_category <-
  sota %>% 
  drop_na(metric_result, metric_name) %>% 
  unnest(cols = categories) %>% 
  group_by(categories) %>% 
  count(benchmark_id, metric_name, name = "num_observations") %>% 
  count(num_observations, sort = TRUE, name = "n") %>% 
  ungroup()


observations_by_category %>% 
  group_by(categories) %>% 
  summarize(
    prop_one = n[num_observations == 1] / sum(n),
    n_metrics = sum(n)
  ) %>% 
  mutate(categories = fct_reorder(categories, prop_one, .desc = TRUE)) %>% 
  ggplot(aes(prop_one, categories, size = n_metrics)) +
  geom_point() +
  scale_x_continuous(breaks = scales::breaks_width(0.1)) +
  labs(
    x = "Proportion of metrics with only a single observation",
    title = "Proportion of single observation metrics by category",
    subtitle = "Many metrics are only measured once",
    size = "Number of\ndistinct metrics"
  )
```

Three categories--Knowledge Base, Audio, and Adversarial--only include metrics with a single observation.

## Distinct tasks by category

```{r}
sota %>% 
  unnest(cols = categories) %>% 
  distinct(categories, task) %>% 
  count(categories) %>% 
  mutate(categories = fct_reorder(categories, n)) %>%
  ggplot(aes(n, categories)) +
  geom_point() +
  scale_x_continuous(breaks = scales::breaks_width(width = 10)) +
  labs(
    title = "Number of distinct tasks by category, ",
    subtitle = "Computer vision and NLP have the most tasks"
  )
```


## Percent change

There should be no negative percent change.

```{r}
sota %>% 
  count(percent_change < 0, sort = TRUE) %>% 
  mutate(prop = n / sum(n))
```

11% are (currently) negative.

```{r}
sota %>% 
  unnest(cols = categories) %>% 
  filter(percent_change < 0) %>% 
  count(categories, sort = TRUE) 
```

Most are in Computer Vision (which also has the most data).

```{r}
sota %>% 
  filter(percent_change > 0) %>% 
  unnest(cols = categories) %>% 
  filter(categories != "Playing Games") %>% 
  mutate(
    categories = 
      fct_reorder(categories, percent_change, .desc = TRUE)
  ) %>% 
  ggplot(aes(categories, percent_change)) +
  geom_hline(yintercept = 0, size = 1.5, color = "white") +
  geom_boxplot() +
  scale_y_log10() +
  theme(axis.text.x = element_text(angle = 45))
```

```{r}
computer_vision <-
  sota %>% 
  unnest(categories) %>%  
  filter(categories == "Computer Vision") %>% 
  group_by(task) %>% 
  filter(
    n() > 1,
    all(percent_change > 0)
  ) %>% 
  ungroup()

sota %>% 
  unnest(categories) %>% 
  filter(categories == "Natural Language Processing")

computer_vision %>% 
  count(task, sort = TRUE)
```

```{r}
computer_vision %>% 
  unite(col = "group_", metric_name, task, remove = FALSE) %>% 
  ggplot(aes(days_written_after_first_in_benchmark, percent_change, group = group_)) +
  geom_line(alpha = 0.5) 
```

